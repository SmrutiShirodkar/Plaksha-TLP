{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Dell\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9ZOavV5i5aDq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import beautifulsoup4 as bs\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVirRhh4YsUt",
        "outputId": "4978bae7-cb09-4366-fe8f-ee1840fb34c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(['stopwords', 'punkt', 'wordnet', 'averaged_perceptron_tagger'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ep72ZTOeR7Hd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/2184804780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_data = pd.read_csv('https://raw.githubusercontent.com/afo/data-x-plaksha/master/07a-tools-nlp-basics/data/labeledTrainData.tsv', header=0, \\\n\u001b[0m\u001b[0;32m      2\u001b[0m                     delimiter=\"\\t\", quoting=3)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('https://raw.githubusercontent.com/afo/data-x-plaksha/master/07a-tools-nlp-basics/data/labeledTrainData.tsv', header=0, \\\n",
        "                    delimiter=\"\\t\", quoting=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOzdsRYmSmgU",
        "outputId": "7d16ee25-1521-439c-fefd-afd7b577dedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slezYRtkX5FK",
        "outputId": "6d02f436-1b4b-412b-a90e-c7118c6ba180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . In addition , a security agent (Stacy Haiduk) and her mate (Brian Wimmer) fight hardly against the carnivorous Smilodons. The Sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. The giant animals savagely are stalking its prey and the group run afoul and fight against one nature's most fearsome predators. Furthermore a third Sabretooth more dangerous and slow stalks its victims.<br /><br />The movie delivers the goods with lots of blood and gore as beheading, hair-raising chills,full of scares when the Sabretooths appear with mediocre special effects.The story provides exciting and stirring entertainment but it results to be quite boring .The giant animals are majority made by computer generator and seem totally lousy .Middling performances though the players reacting appropriately to becoming food.Actors give vigorously physical performances dodging the beasts ,running,bound and leaps or dangling over walls . And it packs a ridiculous final deadly scene. No for small kids by realistic,gory and violent attack scenes . Other films about Sabretooths or Smilodon are the following : ¨Sabretooth(2002)¨by James R Hickox with Vanessa Angel, David Keith and John Rhys Davies and the much better ¨10.000 BC(2006)¨ by Roland Emmerich with with Steven Strait, Cliff Curtis and Camilla Belle. This motion picture filled with bloody moments is badly directed by George Miller and with no originality because takes too many elements from previous films. Miller is an Australian director usually working for television (Tidal wave, Journey to the center of the earth, and many others) and occasionally for cinema ( The man from Snowy river, Zeus and Roxanne,Robinson Crusoe ). Rating : Below average, bottom of barrel.\"\n",
            "\"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . In addition , a security agent (Stacy Haiduk) and her mate (Brian Wimmer) fight hardly against the carnivorous Smilodons. The Sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. The giant animals savagely are stalking its prey and the group run afoul and fight against one nature's most fearsome predators. Furthermore a third Sabretooth more dangerous and slow stalks its victims.The movie delivers the goods with lots o\n"
          ]
        }
      ],
      "source": [
        "review3 = train_data['review'][2] # the review used for initial analysis\n",
        "print(review3)\n",
        "review3 = bs.BeautifulSoup(review3,features='lxml').text # removes HTML tags\n",
        "print(review3[:1150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmp9CrxqYK8d",
        "outputId": "542f4d51-96d4-46e8-eb84-60801a6d9681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20\n",
            "20\n",
            "\n",
            "The film starts with a manager Nicholas Bell giving welcome investors Robert Carradine to Primal Park    A secret project mutating a primal animal using fossilized DNA like Jurassik Park and some scientists resurrect one of natures most fearsome predators the Sabretooth tiger or Smilodon    Scientific ambition turns deadly however and when the high voltage fence is opened the creature escape and begins savagely stalking its prey  the human visitors  tourists and scientific  Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large prehistorical animals which are deadlier and bigger    In addition  a security agent Stacy Haiduk and her mate Brian Wimmer fight hardly against the carnivorous Smilodons   The Sabretooths themselves  of course are the real star stars and they are astounding terrifyingly though not convincing   The giant animals savagely are stalking its prey and the group run afoul and fight against one natures most fearsome predators   Furthermore a third Sabretooth more dangerous and slow stalks its victims  The movie delivers the goods with lots of blood and gore as beheading hairraising chillsfull of scares when the Sabretooths appear with mediocre special effects  The story provides exciting and stirring entertainment but it results to be quite boring   The giant animals are majority made by computer generator and seem totally lousy   Middling performances though the players reacting appropriately to becoming food  Actors give vigorously physical performances dodging the beasts runningbound and leaps or dangling over walls    And it packs a ridiculous final deadly scene   No for small kids by realisticgory and violent attack scenes    Other films about Sabretooths or Smilodon are the following  Sabretoothby James R Hickox with Vanessa Angel David Keith and John Rhys Davies and the much better    BC by Roland Emmerich with with Steven Strait Cliff Curtis and Camilla Belle   This motion picture filled with bloody moments is badly directed by George Miller and with no originality because takes too many elements from previous films   Miller is an Australian director usually working for television Tidal wave Journey to the center of the earth and many others and occasionally for cinema  The man from Snowy river Zeus and RoxanneRobinson Crusoe    Rating  Below average bottom of barrel  \n"
          ]
        }
      ],
      "source": [
        "print(len(sent_tokenize(review3)))\n",
        "sent_tokenize(review3) # doesn't really split all sentences\n",
        "# Check if it does a better job if we add space after every period\n",
        "review3 = review3.replace('.','. ')\n",
        "\n",
        "print(len(sent_tokenize(review3)), end='\\n\\n') # number of sentences\n",
        "\n",
        "review3 = re.sub('[^a-zA-Z ]' ,'',review3)\n",
        "print(review3) # remove special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwOILCDRY2Sy",
        "outputId": "dac11ea1-232e-487a-8938-eab5f5575fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'film', 'starts', 'with', 'a', 'manager', 'nicholas', 'bell', 'giving', 'welcome']\n"
          ]
        }
      ],
      "source": [
        "review3 = review3.lower()\n",
        "\n",
        "review3_words = review3.split()\n",
        "print(review3_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iTozLDIJPyUV"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "def review_cleaner(review):\n",
        "    '''\n",
        "    Clean and preprocess a review.\n",
        "    \n",
        "    1. Remove HTML tags\n",
        "    2. Use regex to remove all special characters (only keep letters)\n",
        "    3. Make strings to lower case and tokenize / word split reviews\n",
        "    4. Remove English stopwords\n",
        "    5. Rejoin to one string\n",
        "    '''\n",
        "    \n",
        "    #1. Remove HTML tags\n",
        "    review = bs.BeautifulSoup(review).text\n",
        "    \n",
        "    #2. Use regex to find emoticons\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
        "    \n",
        "    #3. Remove punctuation\n",
        "    review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
        "    \n",
        "    #4. Tokenize into words (all lower case)\n",
        "    review = review.lower().split()\n",
        "    \n",
        "    #5. Remove stopwords\n",
        "    eng_stopwords = set(stopwords.words(\"english\"))\n",
        "    review = [w for w in review if not w in eng_stopwords]\n",
        "    \n",
        "    #6. Join the review to one sentence\n",
        "    review = ' '.join(review+emoticons)\n",
        "    # add emoticons to the end\n",
        "\n",
        "    return(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG7KXJZfZS-_",
        "outputId": "ed34dc98-2bf1-4032-9e11-0bb8a26ecb5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done with 500 reviews\n",
            "Done with 1000 reviews\n",
            "Done with 1500 reviews\n",
            "Done with 2000 reviews\n",
            "Done with 2500 reviews\n",
            "Done with 3000 reviews\n",
            "Done with 3500 reviews\n",
            "Done with 4000 reviews\n",
            "Done with 4500 reviews\n",
            "Done with 5000 reviews\n",
            "Done with 5500 reviews\n",
            "Done with 6000 reviews\n",
            "Done with 6500 reviews\n",
            "Done with 7000 reviews\n",
            "Done with 7500 reviews\n",
            "Done with 8000 reviews\n",
            "Done with 8500 reviews\n",
            "Done with 9000 reviews\n",
            "Done with 9500 reviews\n",
            "Done with 10000 reviews\n",
            "Done with 10500 reviews\n",
            "Done with 11000 reviews\n",
            "Done with 11500 reviews\n",
            "Done with 12000 reviews\n",
            "Done with 12500 reviews\n",
            "Done with 13000 reviews\n",
            "Done with 13500 reviews\n",
            "Done with 14000 reviews\n",
            "Done with 14500 reviews\n",
            "Done with 15000 reviews\n",
            "Done with 15500 reviews\n",
            "Done with 16000 reviews\n",
            "Done with 16500 reviews\n",
            "Done with 17000 reviews\n",
            "Done with 17500 reviews\n",
            "Done with 18000 reviews\n",
            "Done with 18500 reviews\n",
            "Done with 19000 reviews\n",
            "Done with 19500 reviews\n",
            "Done with 20000 reviews\n",
            "Done with 20500 reviews\n",
            "Done with 21000 reviews\n",
            "Done with 21500 reviews\n",
            "Done with 22000 reviews\n",
            "Done with 22500 reviews\n",
            "Done with 23000 reviews\n",
            "Done with 23500 reviews\n",
            "Done with 24000 reviews\n",
            "Done with 24500 reviews\n",
            "Done with 25000 reviews\n",
            "CPU times: user 18.8 s, sys: 839 ms, total: 19.7 s\n",
            "Wall time: 20 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "num_reviews = len(train_data['review'])\n",
        "\n",
        "review_clean_original = []\n",
        "\n",
        "for i in range(0,num_reviews):\n",
        "    if( (i+1)%500 == 0 ):\n",
        "        # print progress\n",
        "        print(\"Done with %d reviews\" %(i+1)) \n",
        "    review_clean_original.append(review_cleaner(train_data['review'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0zshlp4NaC34"
      },
      "outputs": [],
      "source": [
        "## Example code BoW\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "sent1 = \"cool students study cool data science\"\n",
        "sent2 = \"to know data science study data science\"\n",
        "\n",
        "vect = CountVectorizer() #instantiate\n",
        "vect2 = TfidfVectorizer()\n",
        "\n",
        "sents = np.array([sent1,sent2])\n",
        "\n",
        "vect.fit(sents);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EEO6fZjattm",
        "outputId": "c761e75e-18e7-4713-966b-c97c7518f1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of words in the vocabulary (and position in feature matrix):\n",
            "\n",
            "{'cool': 0, 'students': 4, 'study': 5, 'data': 1, 'science': 3, 'to': 6, 'know': 2}\n"
          ]
        }
      ],
      "source": [
        "print('Total number of words in the vocabulary (and position in feature matrix):\\n')\n",
        "print(vect.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM_SbrKfa6rk",
        "outputId": "e37db862-2c69-4d53-9dff-5e2aa8621798"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 1, 0, 1, 1, 1, 0],\n",
              "       [0, 2, 1, 2, 0, 1, 1]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform to get feature vectors\n",
        "\n",
        "bag = vect.transform(sents)\n",
        "\n",
        "bag.toarray()\n",
        "\n",
        "# the rows corresponds to the sentences "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0KYxt47a_a1",
        "outputId": "ef34314d-adf8-467f-8df4-e4c28de38282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['cool', 'data', 'know', 'science', 'students', 'study', 'to']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.get_feature_names() # stored in the right places"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "VJ7za50sbCLF",
        "outputId": "ae99cb92-5d19-4707-eedd-c141bfb98bda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-245f3cca-d691-4dba-aefb-222495be5405\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cool</th>\n",
              "      <th>data</th>\n",
              "      <th>know</th>\n",
              "      <th>science</th>\n",
              "      <th>students</th>\n",
              "      <th>study</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cool students study cool data science</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to know data science study data science</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245f3cca-d691-4dba-aefb-222495be5405')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-245f3cca-d691-4dba-aefb-222495be5405 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-245f3cca-d691-4dba-aefb-222495be5405');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                         cool  data  know  ...  students  study  to\n",
              "cool students study cool data science       2     1     0  ...         1      1   0\n",
              "to know data science study data science     0     2     1  ...         0      1   1\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Put it in a DataFrame for interpretability\n",
        "\n",
        "pd.DataFrame(bag.toarray(), columns=vect.get_feature_names(), index=[sent1,sent2])\n",
        "\n",
        "# the number in the DataFrame is called Raw Term frequency raw term frequencies: \n",
        "# tf (t,d)—the number of times a term t occurs in a document d."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AA9VsJUbD55",
        "outputId": "85d7eddf-7625-4d21-c5da-1e0f6470f9cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abandoned', 'abc', 'abilities', 'ability', 'able', 'abraham', 'absence', 'absent', 'absolute', 'absolutely']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics # for confusion matrix, accuracy score etc\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\\\n",
        "    review_clean_original, train_data['sentiment'], random_state=0, test_size=.2)\n",
        "\n",
        "\n",
        "# CountVectorizer can actucally handle a lot of the preprocessing for us\n",
        "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             max_features = 5000)\n",
        "\n",
        "vectorizer.fit(X_train)\n",
        "print(vectorizer.get_feature_names()[:10])\n",
        "train_bag = vectorizer.transform(X_train) #transform to a feature matrix\n",
        "test_bag = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsA8up-cbrml",
        "outputId": "0cfbba01-8ebe-4248-c019-aa873e7ed825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 5000)\n",
            "(5000, 5000)\n",
            "  (0, 37)\t1\n",
            "  (0, 41)\t1\n",
            "  (0, 46)\t1\n",
            "  (0, 51)\t1\n",
            "  (0, 58)\t1\n",
            "  (0, 103)\t1\n",
            "  (0, 126)\t1\n",
            "  (0, 142)\t2\n",
            "  (0, 145)\t1\n",
            "  (0, 147)\t1\n",
            "  (0, 162)\t1\n",
            "  (0, 194)\t2\n",
            "  (0, 205)\t1\n",
            "  (0, 265)\t1\n",
            "  (0, 286)\t1\n",
            "  (0, 315)\t1\n",
            "  (0, 327)\t2\n",
            "  (0, 335)\t1\n",
            "  (0, 368)\t1\n",
            "  (0, 395)\t1\n",
            "  (0, 411)\t1\n",
            "  (0, 436)\t1\n",
            "  (0, 475)\t1\n",
            "  (0, 480)\t1\n",
            "  (0, 485)\t1\n",
            "  :\t:\n",
            "  (19999, 3301)\t1\n",
            "  (19999, 3385)\t1\n",
            "  (19999, 3551)\t1\n",
            "  (19999, 3643)\t1\n",
            "  (19999, 3762)\t1\n",
            "  (19999, 3824)\t2\n",
            "  (19999, 3877)\t2\n",
            "  (19999, 3885)\t1\n",
            "  (19999, 3886)\t2\n",
            "  (19999, 3914)\t2\n",
            "  (19999, 3970)\t2\n",
            "  (19999, 4057)\t1\n",
            "  (19999, 4095)\t1\n",
            "  (19999, 4102)\t1\n",
            "  (19999, 4191)\t1\n",
            "  (19999, 4248)\t1\n",
            "  (19999, 4279)\t1\n",
            "  (19999, 4473)\t1\n",
            "  (19999, 4474)\t1\n",
            "  (19999, 4619)\t1\n",
            "  (19999, 4699)\t1\n",
            "  (19999, 4766)\t1\n",
            "  (19999, 4811)\t1\n",
            "  (19999, 4853)\t1\n",
            "  (19999, 4892)\t1\n"
          ]
        }
      ],
      "source": [
        "print(train_bag.toarray().shape) # 20,000 reviews, 2,000 feartures. just as expected\n",
        "print(test_bag.toarray().shape)\n",
        "type(train_bag) # sparse matrix representation\n",
        "print(train_bag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4Teo9SrmfNSV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# put everything together in a function\n",
        "\n",
        "def predict_sentiment(cleaned_reviews, y=train_data[\"sentiment\"]):\n",
        "\n",
        "    print(\"Creating the bag of words model!\\n\")\n",
        "    # CountVectorizer\" is scikit-learn's bag of words tool, here we show more keywords \n",
        "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
        "                                 tokenizer = None,    \\\n",
        "                                 preprocessor = None, \\\n",
        "                                 stop_words = None,   \\\n",
        "                                 max_features = 2000) \n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\\\n",
        "    cleaned_reviews, y, random_state=0, test_size=.2)\n",
        "\n",
        "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
        "    # then transform the data into feature vectors.\n",
        "    # The input should be a list of strings. .toarraty() converts to a numpy array\n",
        "    \n",
        "    train_bag = vectorizer.fit_transform(X_train).toarray()\n",
        "    test_bag = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "    # You can extract the vocabulary created by CountVectorizer\n",
        "    # by running print(vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "    print(\"Training the random forest classifier!\\n\")\n",
        "    # Initialize a Random Forest classifier with 50 trees\n",
        "    forest = RandomForestClassifier(n_estimators = 50) \n",
        "\n",
        "    # Fit the forest to the training set, using the bag of words as \n",
        "    # features and the sentiment labels as the target variable\n",
        "    forest = forest.fit(train_bag, y_train)\n",
        "\n",
        "\n",
        "    train_predictions = forest.predict(train_bag)\n",
        "    test_predictions = forest.predict(test_bag)\n",
        "    \n",
        "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
        "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
        "    print(\"The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
        "    \n",
        "    return(forest,vectorizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z80uV373foT3",
        "outputId": "81ff6554-f0a9-4114-fda2-2b7a3ed7a0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Reviews\n",
            "Creating the bag of words model!\n",
            "\n",
            "Training the random forest classifier!\n",
            "\n",
            "The training accuracy is:  1.0 \n",
            " The validation accuracy is:  0.833\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "print('Original Reviews')\n",
        "forest1,vec1 = predict_sentiment(review_clean_original)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ProjectDS-3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
