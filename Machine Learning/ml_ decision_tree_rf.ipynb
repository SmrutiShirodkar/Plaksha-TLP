{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLLab4HW",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPHXtImFSivd"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvZrVdLPVTUQ",
        "outputId": "60b4e3e3-35fa-448f-84f0-20eb87664590"
      },
      "source": [
        "b_c_data=load_breast_cancer()\n",
        "X,y=load_breast_cancer(return_X_y=True,as_frame=False)\n",
        "print(X,y)\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,random_state=1)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "(426, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a76P-tqRwSAs"
      },
      "source": [
        "**(i) Use Keras or any other framework to construct a decision tree from the training data and obtain the performance on the test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR_AAt5GbvGw",
        "outputId": "780d0592-7cec-4463-bb44-b21142055117"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "dt_accuracy=0\n",
        "rf_accuracy=0\n",
        "dt = tree.DecisionTreeClassifier(random_state=10)\n",
        "kf = KFold(n_splits=5,shuffle=True,random_state=10)\n",
        "for k, (train_indices, test_indices) in enumerate(kf.split(X)):\n",
        "  X_train, X_test = X[train_indices], X[test_indices]\n",
        "  y_train, y_test = y[train_indices], y[test_indices]\n",
        "  dt.fit(X[train_indices], y[train_indices])\n",
        "  dt_accuracy+=dt.score(X[test_indices], y[test_indices])*100\n",
        "  print(\n",
        "      \"[fold {0}] score: {1:.5f}\".format(\n",
        "          k, dt.score(X[test_indices], y[test_indices])*100)\n",
        "      )\n",
        "print('Mean DT accuracy:', dt_accuracy/5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] score: 85.96491\n",
            "[fold 1] score: 95.61404\n",
            "[fold 2] score: 91.22807\n",
            "[fold 3] score: 92.10526\n",
            "[fold 4] score: 92.03540\n",
            "Mean DT accuracy: 91.38953578636857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs1VNtTtwZq1"
      },
      "source": [
        "**(ii) Construct a random forest (of say, 100 trees) from the training data and use the random forest to obtain the performance on the test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUwEVnPBf9Vd",
        "outputId": "38332cd2-3778-46dc-9f03-8b41f5f0905a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=10)\n",
        "kf = KFold(n_splits=5,shuffle=True,random_state=10)\n",
        "dt_accuracy=0\n",
        "rf_accuracy=0\n",
        "for k, (train_indices, test_indices) in enumerate(kf.split(X)):\n",
        "  X_train, X_test = X[train_indices], X[test_indices]\n",
        "  y_train, y_test = y[train_indices], y[test_indices]\n",
        "  rf.fit(X[train_indices], y[train_indices])\n",
        "  rf_accuracy+=rf.score(X[test_indices], y[test_indices])*100\n",
        "  print(\n",
        "      \"[fold {0}] score: {1:.5f}\".format(\n",
        "          k, rf.score(X[test_indices], y[test_indices])*100)\n",
        "      )\n",
        "print('Mean RF accuracy:', rf_accuracy/5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] score: 98.24561\n",
            "[fold 1] score: 98.24561\n",
            "[fold 2] score: 95.61404\n",
            "[fold 3] score: 94.73684\n",
            "[fold 4] score: 92.03540\n",
            "Mean RF accuracy: 95.77550069864928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2h6ac52wJll"
      },
      "source": [
        "**(iii) Compare the performance you obtain in (i) and (ii)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V_22zEDnEf8"
      },
      "source": [
        "On comparing the above two models, it is noted that the average accuracy score of Random Forest model is better than the the average accuracy score of Decision Tree model. This can be because of the extra randomness of the Random Forest algorithm with the increase in trees and searches for the best features among all the features. Thus, the algorithm results in greater tree diversity, which trades a higher bias for a lower variance, generally yielding an overall better model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWBWvN8nu_Ia",
        "outputId": "43eb5941-4720-405c-9221-891f7c659eaf"
      },
      "source": [
        "dt_accuracy=0\n",
        "rf_accuracy=0\n",
        "for k, (train_indices, test_indices) in enumerate(kf.split(X)):\n",
        "  X_train, X_test = X[train_indices], X[test_indices]\n",
        "  y_train, y_test = y[train_indices], y[test_indices]\n",
        "  dt.fit(X[train_indices], y[train_indices])\n",
        "  '''print(\n",
        "      \"[fold {0}] Decision Tree score: {1:.5f}\".format(\n",
        "          k, dt.score(X[test_indices], y[test_indices])*100)\n",
        "      )'''\n",
        "  dt_accuracy+=dt.score(X[test_indices], y[test_indices])*100\n",
        "  rf.fit(X[train_indices], y[train_indices])\n",
        "  '''print(\n",
        "      \"[fold {0}] Random Forest Classifier score: {1:.5f}\".format(\n",
        "          k, rf.score(X[test_indices], y[test_indices])*100)\n",
        "      )'''\n",
        "  rf_accuracy+=rf.score(X[test_indices], y[test_indices])*100\n",
        "print('Mean DT accuracy:', dt_accuracy/5)\n",
        "print('Mean RF accuracy:', rf_accuracy/5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean DT accuracy: 91.38953578636857\n",
            "Mean RF accuracy: 95.77550069864928\n"
          ]
        }
      ]
    }
  ]
}